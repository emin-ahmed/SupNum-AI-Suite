[{"loss": 33.8439, "grad_norm": 4.295335292816162, "learning_rate": 0.0003, "epoch": 0.02631578947368421, "step": 1}, {"loss": 34.1688, "grad_norm": 4.7342705726623535, "learning_rate": 0.00029842105263157894, "epoch": 0.05263157894736842, "step": 2}, {"loss": 33.5202, "grad_norm": 4.50330924987793, "learning_rate": 0.00029684210526315785, "epoch": 0.07894736842105263, "step": 3}, {"loss": 33.9243, "grad_norm": 4.765766620635986, "learning_rate": 0.0002952631578947368, "epoch": 0.10526315789473684, "step": 4}, {"loss": 32.5893, "grad_norm": 4.914977550506592, "learning_rate": 0.0002936842105263158, "epoch": 0.13157894736842105, "step": 5}, {"loss": 30.3785, "grad_norm": 4.763262748718262, "learning_rate": 0.0002921052631578947, "epoch": 0.15789473684210525, "step": 6}, {"loss": 34.6062, "grad_norm": 7.041215419769287, "learning_rate": 0.00029052631578947366, "epoch": 0.18421052631578946, "step": 7}, {"loss": 34.0142, "grad_norm": 7.4709625244140625, "learning_rate": 0.00028894736842105263, "epoch": 0.21052631578947367, "step": 8}, {"loss": 32.901, "grad_norm": 7.1478352546691895, "learning_rate": 0.00028736842105263154, "epoch": 0.23684210526315788, "step": 9}, {"loss": 34.2491, "grad_norm": 7.095200061798096, "learning_rate": 0.0002857894736842105, "epoch": 0.2631578947368421, "step": 10}, {"loss": 31.4033, "grad_norm": 8.680612564086914, "learning_rate": 0.0002842105263157894, "epoch": 0.2894736842105263, "step": 11}, {"loss": 31.3152, "grad_norm": 8.349114418029785, "learning_rate": 0.0002826315789473684, "epoch": 0.3157894736842105, "step": 12}, {"loss": 32.2311, "grad_norm": 7.85225248336792, "learning_rate": 0.00028105263157894735, "epoch": 0.34210526315789475, "step": 13}, {"loss": 27.341, "grad_norm": 7.415923118591309, "learning_rate": 0.0002794736842105263, "epoch": 0.3684210526315789, "step": 14}, {"loss": 28.3182, "grad_norm": 6.743043422698975, "learning_rate": 0.00027789473684210523, "epoch": 0.39473684210526316, "step": 15}, {"loss": 31.8433, "grad_norm": 8.693730354309082, "learning_rate": 0.0002763157894736842, "epoch": 0.42105263157894735, "step": 16}, {"loss": 28.6301, "grad_norm": 8.265623092651367, "learning_rate": 0.0002747368421052631, "epoch": 0.4473684210526316, "step": 17}, {"loss": 30.8889, "grad_norm": 9.285086631774902, "learning_rate": 0.00027315789473684207, "epoch": 0.47368421052631576, "step": 18}, {"loss": 26.0866, "grad_norm": 7.869828701019287, "learning_rate": 0.00027157894736842104, "epoch": 0.5, "step": 19}, {"loss": 26.5381, "grad_norm": 7.271572113037109, "learning_rate": 0.00027, "epoch": 0.5263157894736842, "step": 20}, {"loss": 29.9047, "grad_norm": 9.093578338623047, "learning_rate": 0.0002684210526315789, "epoch": 0.5526315789473685, "step": 21}, {"loss": 27.7774, "grad_norm": 9.2013578414917, "learning_rate": 0.0002668421052631579, "epoch": 0.5789473684210527, "step": 22}, {"loss": 27.9883, "grad_norm": 7.216761112213135, "learning_rate": 0.0002652631578947368, "epoch": 0.6052631578947368, "step": 23}, {"loss": 26.1099, "grad_norm": 7.007810115814209, "learning_rate": 0.00026368421052631576, "epoch": 0.631578947368421, "step": 24}, {"loss": 25.3953, "grad_norm": 8.297680854797363, "learning_rate": 0.0002621052631578947, "epoch": 0.6578947368421053, "step": 25}, {"loss": 25.0345, "grad_norm": 6.766289234161377, "learning_rate": 0.0002605263157894737, "epoch": 0.6842105263157895, "step": 26}, {"loss": 25.0639, "grad_norm": 6.685275554656982, "learning_rate": 0.0002589473684210526, "epoch": 0.7105263157894737, "step": 27}, {"loss": 22.7638, "grad_norm": 6.176820755004883, "learning_rate": 0.00025736842105263157, "epoch": 0.7368421052631579, "step": 28}, {"loss": 22.9083, "grad_norm": 6.163325309753418, "learning_rate": 0.0002557894736842105, "epoch": 0.7631578947368421, "step": 29}, {"loss": 24.374, "grad_norm": 6.912463188171387, "learning_rate": 0.00025421052631578945, "epoch": 0.7894736842105263, "step": 30}, {"loss": 23.4441, "grad_norm": 6.095834255218506, "learning_rate": 0.00025263157894736836, "epoch": 0.8157894736842105, "step": 31}, {"loss": 23.0261, "grad_norm": 6.334493637084961, "learning_rate": 0.0002510526315789474, "epoch": 0.8421052631578947, "step": 32}, {"loss": 21.2805, "grad_norm": 6.585384368896484, "learning_rate": 0.0002494736842105263, "epoch": 0.868421052631579, "step": 33}, {"loss": 23.0916, "grad_norm": 7.768247127532959, "learning_rate": 0.00024789473684210526, "epoch": 0.8947368421052632, "step": 34}, {"loss": 21.5505, "grad_norm": 6.201193809509277, "learning_rate": 0.00024631578947368417, "epoch": 0.9210526315789473, "step": 35}, {"loss": 21.4674, "grad_norm": 6.857501029968262, "learning_rate": 0.00024473684210526314, "epoch": 0.9473684210526315, "step": 36}, {"loss": 20.888, "grad_norm": 7.625669956207275, "learning_rate": 0.00024315789473684207, "epoch": 0.9736842105263158, "step": 37}, {"loss": 20.0621, "grad_norm": 8.76364803314209, "learning_rate": 0.000241578947368421, "epoch": 1.0, "step": 38}, {"loss": 18.8981, "grad_norm": 6.981417179107666, "learning_rate": 0.00023999999999999998, "epoch": 1.0263157894736843, "step": 39}, {"loss": 18.1224, "grad_norm": 6.4769287109375, "learning_rate": 0.00023842105263157895, "epoch": 1.0526315789473684, "step": 40}, {"loss": 18.1259, "grad_norm": 7.100368022918701, "learning_rate": 0.00023684210526315788, "epoch": 1.0789473684210527, "step": 41}, {"loss": 18.1055, "grad_norm": 7.284247398376465, "learning_rate": 0.00023526315789473682, "epoch": 1.1052631578947367, "step": 42}, {"loss": 18.3758, "grad_norm": 7.696409702301025, "learning_rate": 0.00023368421052631576, "epoch": 1.131578947368421, "step": 43}, {"loss": 18.6623, "grad_norm": 8.715065956115723, "learning_rate": 0.0002321052631578947, "epoch": 1.1578947368421053, "step": 44}, {"loss": 17.1095, "grad_norm": 7.307533264160156, "learning_rate": 0.00023052631578947364, "epoch": 1.1842105263157894, "step": 45}, {"loss": 16.5196, "grad_norm": 8.428132057189941, "learning_rate": 0.00022894736842105263, "epoch": 1.2105263157894737, "step": 46}, {"loss": 15.5979, "grad_norm": 7.077114105224609, "learning_rate": 0.00022736842105263157, "epoch": 1.236842105263158, "step": 47}, {"loss": 14.9805, "grad_norm": 7.755094051361084, "learning_rate": 0.0002257894736842105, "epoch": 1.263157894736842, "step": 48}, {"loss": 16.2719, "grad_norm": 9.26889705657959, "learning_rate": 0.00022421052631578945, "epoch": 1.2894736842105263, "step": 49}, {"loss": 15.2613, "grad_norm": 9.027280807495117, "learning_rate": 0.0002226315789473684, "epoch": 1.3157894736842106, "step": 50}, {"loss": 13.9932, "grad_norm": 8.686690330505371, "learning_rate": 0.00022105263157894733, "epoch": 1.3421052631578947, "step": 51}, {"loss": 15.0289, "grad_norm": 9.271195411682129, "learning_rate": 0.00021947368421052632, "epoch": 1.368421052631579, "step": 52}, {"loss": 12.6785, "grad_norm": 8.968231201171875, "learning_rate": 0.00021789473684210526, "epoch": 1.3947368421052633, "step": 53}, {"loss": 13.2474, "grad_norm": 9.920008659362793, "learning_rate": 0.0002163157894736842, "epoch": 1.4210526315789473, "step": 54}, {"loss": 12.3653, "grad_norm": 10.43732738494873, "learning_rate": 0.00021473684210526314, "epoch": 1.4473684210526316, "step": 55}, {"loss": 10.8121, "grad_norm": 9.762856483459473, "learning_rate": 0.00021315789473684208, "epoch": 1.4736842105263157, "step": 56}, {"loss": 10.9258, "grad_norm": 8.565693855285645, "learning_rate": 0.00021157894736842102, "epoch": 1.5, "step": 57}, {"loss": 10.4262, "grad_norm": 9.287610054016113, "learning_rate": 0.00020999999999999998, "epoch": 1.526315789473684, "step": 58}, {"loss": 10.4756, "grad_norm": 10.172697067260742, "learning_rate": 0.00020842105263157895, "epoch": 1.5526315789473686, "step": 59}, {"loss": 9.5601, "grad_norm": 9.8132963180542, "learning_rate": 0.0002068421052631579, "epoch": 1.5789473684210527, "step": 60}, {"loss": 9.1568, "grad_norm": 7.960564136505127, "learning_rate": 0.00020526315789473683, "epoch": 1.6052631578947367, "step": 61}, {"loss": 8.5737, "grad_norm": 8.141860008239746, "learning_rate": 0.00020368421052631576, "epoch": 1.631578947368421, "step": 62}, {"loss": 7.7315, "grad_norm": 6.436052322387695, "learning_rate": 0.0002021052631578947, "epoch": 1.6578947368421053, "step": 63}, {"loss": 6.9628, "grad_norm": 5.233346939086914, "learning_rate": 0.00020052631578947367, "epoch": 1.6842105263157894, "step": 64}, {"loss": 7.3402, "grad_norm": 5.632781505584717, "learning_rate": 0.0001989473684210526, "epoch": 1.7105263157894737, "step": 65}, {"loss": 7.2932, "grad_norm": 11.792522430419922, "learning_rate": 0.00019736842105263157, "epoch": 1.736842105263158, "step": 66}, {"loss": 6.3105, "grad_norm": 3.6388285160064697, "learning_rate": 0.0001957894736842105, "epoch": 1.763157894736842, "step": 67}, {"loss": 6.2814, "grad_norm": 3.210435390472412, "learning_rate": 0.00019421052631578945, "epoch": 1.7894736842105263, "step": 68}, {"loss": 6.0502, "grad_norm": 2.8135976791381836, "learning_rate": 0.0001926315789473684, "epoch": 1.8157894736842106, "step": 69}, {"loss": 5.7343, "grad_norm": 2.9593143463134766, "learning_rate": 0.00019105263157894736, "epoch": 1.8421052631578947, "step": 70}, {"loss": 5.7125, "grad_norm": 2.2559800148010254, "learning_rate": 0.0001894736842105263, "epoch": 1.868421052631579, "step": 71}, {"loss": 5.7668, "grad_norm": 2.314319372177124, "learning_rate": 0.00018789473684210524, "epoch": 1.8947368421052633, "step": 72}, {"loss": 5.7014, "grad_norm": 2.3951778411865234, "learning_rate": 0.0001863157894736842, "epoch": 1.9210526315789473, "step": 73}, {"loss": 5.5419, "grad_norm": 2.033560037612915, "learning_rate": 0.00018473684210526314, "epoch": 1.9473684210526314, "step": 74}, {"loss": 5.6015, "grad_norm": 2.0203728675842285, "learning_rate": 0.00018315789473684208, "epoch": 1.973684210526316, "step": 75}, {"loss": 5.4371, "grad_norm": 1.5657329559326172, "learning_rate": 0.00018157894736842105, "epoch": 2.0, "step": 76}, {"loss": 5.6797, "grad_norm": 1.8990586996078491, "learning_rate": 0.00017999999999999998, "epoch": 2.026315789473684, "step": 77}, {"loss": 5.3684, "grad_norm": 2.036844253540039, "learning_rate": 0.00017842105263157892, "epoch": 2.0526315789473686, "step": 78}, {"loss": 5.0744, "grad_norm": 1.2138025760650635, "learning_rate": 0.00017684210526315786, "epoch": 2.0789473684210527, "step": 79}, {"loss": 5.2997, "grad_norm": 1.4484648704528809, "learning_rate": 0.00017526315789473683, "epoch": 2.1052631578947367, "step": 80}, {"loss": 5.1592, "grad_norm": 1.224920630455017, "learning_rate": 0.0001736842105263158, "epoch": 2.1315789473684212, "step": 81}, {"loss": 5.2102, "grad_norm": 1.2252742052078247, "learning_rate": 0.00017210526315789473, "epoch": 2.1578947368421053, "step": 82}, {"loss": 5.0477, "grad_norm": 1.1630173921585083, "learning_rate": 0.00017052631578947367, "epoch": 2.1842105263157894, "step": 83}, {"loss": 5.2211, "grad_norm": 1.6621229648590088, "learning_rate": 0.0001689473684210526, "epoch": 2.2105263157894735, "step": 84}, {"loss": 5.0016, "grad_norm": 0.8580025434494019, "learning_rate": 0.00016736842105263155, "epoch": 2.236842105263158, "step": 85}, {"loss": 4.9614, "grad_norm": 1.0849230289459229, "learning_rate": 0.00016578947368421052, "epoch": 2.263157894736842, "step": 86}, {"loss": 4.9788, "grad_norm": 1.0956881046295166, "learning_rate": 0.00016421052631578948, "epoch": 2.2894736842105265, "step": 87}, {"loss": 4.8842, "grad_norm": 0.8716070055961609, "learning_rate": 0.00016263157894736842, "epoch": 2.3157894736842106, "step": 88}, {"loss": 4.9225, "grad_norm": 1.0003867149353027, "learning_rate": 0.00016105263157894736, "epoch": 2.3421052631578947, "step": 89}, {"loss": 4.8851, "grad_norm": 0.769956648349762, "learning_rate": 0.0001594736842105263, "epoch": 2.3684210526315788, "step": 90}, {"loss": 4.8635, "grad_norm": 0.8806421756744385, "learning_rate": 0.00015789473684210524, "epoch": 2.3947368421052633, "step": 91}, {"loss": 4.8286, "grad_norm": 0.7751848697662354, "learning_rate": 0.00015631578947368418, "epoch": 2.4210526315789473, "step": 92}, {"loss": 4.8244, "grad_norm": 1.0735254287719727, "learning_rate": 0.00015473684210526317, "epoch": 2.4473684210526314, "step": 93}, {"loss": 6.1087, "grad_norm": 17.05156135559082, "learning_rate": 0.0001531578947368421, "epoch": 2.473684210526316, "step": 94}, {"loss": 4.7859, "grad_norm": 0.7408082485198975, "learning_rate": 0.00015157894736842105, "epoch": 2.5, "step": 95}, {"loss": 4.6455, "grad_norm": 0.6586516499519348, "learning_rate": 0.00015, "epoch": 2.526315789473684, "step": 96}, {"loss": 4.6375, "grad_norm": 0.5803013443946838, "learning_rate": 0.00014842105263157893, "epoch": 2.5526315789473686, "step": 97}, {"loss": 4.7948, "grad_norm": 0.8658038377761841, "learning_rate": 0.0001468421052631579, "epoch": 2.5789473684210527, "step": 98}, {"loss": 4.7543, "grad_norm": 0.7885521650314331, "learning_rate": 0.00014526315789473683, "epoch": 2.6052631578947367, "step": 99}, {"loss": 4.5836, "grad_norm": 0.5565131306648254, "learning_rate": 0.00014368421052631577, "epoch": 2.6315789473684212, "step": 100}, {"loss": 4.5673, "grad_norm": 0.672140896320343, "learning_rate": 0.0001421052631578947, "epoch": 2.6578947368421053, "step": 101}, {"loss": 4.552, "grad_norm": 0.7995172739028931, "learning_rate": 0.00014052631578947367, "epoch": 2.6842105263157894, "step": 102}, {"loss": 4.5366, "grad_norm": 0.7927354574203491, "learning_rate": 0.00013894736842105261, "epoch": 2.7105263157894735, "step": 103}, {"loss": 4.5122, "grad_norm": 0.7219107151031494, "learning_rate": 0.00013736842105263155, "epoch": 2.736842105263158, "step": 104}, {"loss": 4.5554, "grad_norm": 0.6433181166648865, "learning_rate": 0.00013578947368421052, "epoch": 2.763157894736842, "step": 105}, {"loss": 4.7054, "grad_norm": 0.5937933325767517, "learning_rate": 0.00013421052631578946, "epoch": 2.7894736842105265, "step": 106}, {"loss": 4.6145, "grad_norm": 0.5482497215270996, "learning_rate": 0.0001326315789473684, "epoch": 2.8157894736842106, "step": 107}, {"loss": 4.6997, "grad_norm": 0.8725785613059998, "learning_rate": 0.00013105263157894736, "epoch": 2.8421052631578947, "step": 108}, {"loss": 4.5481, "grad_norm": 0.6166408658027649, "learning_rate": 0.0001294736842105263, "epoch": 2.8684210526315788, "step": 109}, {"loss": 4.5399, "grad_norm": 0.5901303291320801, "learning_rate": 0.00012789473684210524, "epoch": 2.8947368421052633, "step": 110}, {"loss": 4.5219, "grad_norm": 0.5658213496208191, "learning_rate": 0.00012631578947368418, "epoch": 2.9210526315789473, "step": 111}, {"loss": 4.5416, "grad_norm": 0.568730890750885, "learning_rate": 0.00012473684210526315, "epoch": 2.9473684210526314, "step": 112}, {"loss": 4.5545, "grad_norm": 0.7930344939231873, "learning_rate": 0.00012315789473684208, "epoch": 2.973684210526316, "step": 113}, {"loss": 4.5972, "grad_norm": 1.028195858001709, "learning_rate": 0.00012157894736842104, "epoch": 3.0, "step": 114}, {"loss": 4.479, "grad_norm": 0.5687513947486877, "learning_rate": 0.00011999999999999999, "epoch": 3.026315789473684, "step": 115}, {"loss": 4.5883, "grad_norm": 1.091465950012207, "learning_rate": 0.00011842105263157894, "epoch": 3.0526315789473686, "step": 116}, {"loss": 4.5572, "grad_norm": 0.8613729476928711, "learning_rate": 0.00011684210526315788, "epoch": 3.0789473684210527, "step": 117}, {"loss": 4.418, "grad_norm": 0.4848554730415344, "learning_rate": 0.00011526315789473682, "epoch": 3.1052631578947367, "step": 118}, {"loss": 4.5256, "grad_norm": 0.6704431176185608, "learning_rate": 0.00011368421052631579, "epoch": 3.1315789473684212, "step": 119}, {"loss": 4.5459, "grad_norm": 0.6065446138381958, "learning_rate": 0.00011210526315789472, "epoch": 3.1578947368421053, "step": 120}, {"loss": 4.5029, "grad_norm": 0.6126711964607239, "learning_rate": 0.00011052631578947366, "epoch": 3.1842105263157894, "step": 121}, {"loss": 4.4336, "grad_norm": 0.48072659969329834, "learning_rate": 0.00010894736842105263, "epoch": 3.2105263157894735, "step": 122}, {"loss": 4.4496, "grad_norm": 0.5583487749099731, "learning_rate": 0.00010736842105263157, "epoch": 3.236842105263158, "step": 123}, {"loss": 4.4983, "grad_norm": 0.6600431203842163, "learning_rate": 0.00010578947368421051, "epoch": 3.263157894736842, "step": 124}, {"loss": 4.4838, "grad_norm": 0.787142813205719, "learning_rate": 0.00010421052631578947, "epoch": 3.2894736842105265, "step": 125}, {"loss": 4.4258, "grad_norm": 0.49874523282051086, "learning_rate": 0.00010263157894736841, "epoch": 3.3157894736842106, "step": 126}, {"loss": 4.3419, "grad_norm": 0.6171314120292664, "learning_rate": 0.00010105263157894735, "epoch": 3.3421052631578947, "step": 127}, {"loss": 4.4641, "grad_norm": 0.5662078261375427, "learning_rate": 9.94736842105263e-05, "epoch": 3.3684210526315788, "step": 128}, {"loss": 4.4633, "grad_norm": 0.6411548256874084, "learning_rate": 9.789473684210526e-05, "epoch": 3.3947368421052633, "step": 129}, {"loss": 4.3684, "grad_norm": 0.9628967642784119, "learning_rate": 9.63157894736842e-05, "epoch": 3.4210526315789473, "step": 130}, {"loss": 4.3915, "grad_norm": 0.544944167137146, "learning_rate": 9.473684210526315e-05, "epoch": 3.4473684210526314, "step": 131}, {"loss": 4.4821, "grad_norm": 0.5629206299781799, "learning_rate": 9.31578947368421e-05, "epoch": 3.473684210526316, "step": 132}, {"loss": 4.404, "grad_norm": 1.2159181833267212, "learning_rate": 9.157894736842104e-05, "epoch": 3.5, "step": 133}, {"loss": 4.3968, "grad_norm": 0.5896735191345215, "learning_rate": 8.999999999999999e-05, "epoch": 3.526315789473684, "step": 134}, {"loss": 4.2858, "grad_norm": 0.5589841604232788, "learning_rate": 8.842105263157893e-05, "epoch": 3.5526315789473686, "step": 135}, {"loss": 4.3788, "grad_norm": 0.5692588090896606, "learning_rate": 8.68421052631579e-05, "epoch": 3.5789473684210527, "step": 136}, {"loss": 4.4696, "grad_norm": 0.5685903429985046, "learning_rate": 8.526315789473684e-05, "epoch": 3.6052631578947367, "step": 137}, {"loss": 4.3546, "grad_norm": 0.47901487350463867, "learning_rate": 8.368421052631578e-05, "epoch": 3.6315789473684212, "step": 138}, {"loss": 4.3624, "grad_norm": 1.1435364484786987, "learning_rate": 8.210526315789474e-05, "epoch": 3.6578947368421053, "step": 139}, {"loss": 4.4834, "grad_norm": 0.553628146648407, "learning_rate": 8.052631578947368e-05, "epoch": 3.6842105263157894, "step": 140}, {"loss": 4.2089, "grad_norm": 0.5789945721626282, "learning_rate": 7.894736842105262e-05, "epoch": 3.7105263157894735, "step": 141}, {"loss": 4.344, "grad_norm": 0.8336247205734253, "learning_rate": 7.736842105263159e-05, "epoch": 3.736842105263158, "step": 142}, {"loss": 4.5004, "grad_norm": 0.5874236226081848, "learning_rate": 7.578947368421052e-05, "epoch": 3.763157894736842, "step": 143}, {"loss": 4.3213, "grad_norm": 0.5230619311332703, "learning_rate": 7.421052631578946e-05, "epoch": 3.7894736842105265, "step": 144}, {"loss": 4.383, "grad_norm": 0.6453795433044434, "learning_rate": 7.263157894736842e-05, "epoch": 3.8157894736842106, "step": 145}, {"loss": 4.1183, "grad_norm": 0.5581768751144409, "learning_rate": 7.105263157894735e-05, "epoch": 3.8421052631578947, "step": 146}, {"loss": 4.3326, "grad_norm": 0.5057665109634399, "learning_rate": 6.947368421052631e-05, "epoch": 3.8684210526315788, "step": 147}, {"loss": 4.3078, "grad_norm": 0.5481233596801758, "learning_rate": 6.789473684210526e-05, "epoch": 3.8947368421052633, "step": 148}, {"loss": 4.3041, "grad_norm": 0.5953482985496521, "learning_rate": 6.63157894736842e-05, "epoch": 3.9210526315789473, "step": 149}, {"loss": 4.2778, "grad_norm": 0.6343435645103455, "learning_rate": 6.473684210526315e-05, "epoch": 3.9473684210526314, "step": 150}, {"loss": 4.4201, "grad_norm": 1.3701930046081543, "learning_rate": 6.315789473684209e-05, "epoch": 3.973684210526316, "step": 151}, {"loss": 4.5459, "grad_norm": 0.970649778842926, "learning_rate": 6.157894736842104e-05, "epoch": 4.0, "step": 152}, {"loss": 4.3035, "grad_norm": 0.5418627262115479, "learning_rate": 5.9999999999999995e-05, "epoch": 4.026315789473684, "step": 153}, {"loss": 4.558, "grad_norm": 1.0680723190307617, "learning_rate": 5.842105263157894e-05, "epoch": 4.052631578947368, "step": 154}, {"loss": 4.2741, "grad_norm": 0.5463693737983704, "learning_rate": 5.684210526315789e-05, "epoch": 4.078947368421052, "step": 155}, {"loss": 4.1783, "grad_norm": 0.604279637336731, "learning_rate": 5.526315789473683e-05, "epoch": 4.105263157894737, "step": 156}, {"loss": 4.3666, "grad_norm": 0.5439284443855286, "learning_rate": 5.3684210526315784e-05, "epoch": 4.131578947368421, "step": 157}, {"loss": 4.3065, "grad_norm": 0.7022172808647156, "learning_rate": 5.210526315789474e-05, "epoch": 4.157894736842105, "step": 158}, {"loss": 4.3229, "grad_norm": 0.6418017148971558, "learning_rate": 5.0526315789473676e-05, "epoch": 4.184210526315789, "step": 159}, {"loss": 4.4081, "grad_norm": 0.5793300867080688, "learning_rate": 4.894736842105263e-05, "epoch": 4.2105263157894735, "step": 160}, {"loss": 4.2338, "grad_norm": 0.5622994303703308, "learning_rate": 4.7368421052631574e-05, "epoch": 4.2368421052631575, "step": 161}, {"loss": 4.3433, "grad_norm": 0.7225457429885864, "learning_rate": 4.578947368421052e-05, "epoch": 4.2631578947368425, "step": 162}, {"loss": 4.3611, "grad_norm": 0.548530101776123, "learning_rate": 4.4210526315789466e-05, "epoch": 4.2894736842105265, "step": 163}, {"loss": 4.0955, "grad_norm": 0.6155149936676025, "learning_rate": 4.263157894736842e-05, "epoch": 4.315789473684211, "step": 164}, {"loss": 4.2772, "grad_norm": 0.5843024849891663, "learning_rate": 4.105263157894737e-05, "epoch": 4.342105263157895, "step": 165}, {"loss": 4.274, "grad_norm": 0.5288644433021545, "learning_rate": 3.947368421052631e-05, "epoch": 4.368421052631579, "step": 166}, {"loss": 4.2284, "grad_norm": 0.7393166422843933, "learning_rate": 3.789473684210526e-05, "epoch": 4.394736842105263, "step": 167}, {"loss": 4.1246, "grad_norm": 0.6369621157646179, "learning_rate": 3.631578947368421e-05, "epoch": 4.421052631578947, "step": 168}, {"loss": 4.297, "grad_norm": 0.6187225580215454, "learning_rate": 3.4736842105263153e-05, "epoch": 4.447368421052632, "step": 169}, {"loss": 4.1804, "grad_norm": 0.4892146587371826, "learning_rate": 3.31578947368421e-05, "epoch": 4.473684210526316, "step": 170}, {"loss": 4.0841, "grad_norm": 0.5207537412643433, "learning_rate": 3.1578947368421045e-05, "epoch": 4.5, "step": 171}, {"loss": 4.272, "grad_norm": 0.5650238990783691, "learning_rate": 2.9999999999999997e-05, "epoch": 4.526315789473684, "step": 172}, {"loss": 4.0968, "grad_norm": 1.829944372177124, "learning_rate": 2.8421052631578946e-05, "epoch": 4.552631578947368, "step": 173}, {"loss": 4.1802, "grad_norm": 0.5879883766174316, "learning_rate": 2.6842105263157892e-05, "epoch": 4.578947368421053, "step": 174}, {"loss": 4.4271, "grad_norm": 0.9941141605377197, "learning_rate": 2.5263157894736838e-05, "epoch": 4.605263157894737, "step": 175}, {"loss": 4.2441, "grad_norm": 0.5927324295043945, "learning_rate": 2.3684210526315787e-05, "epoch": 4.631578947368421, "step": 176}, {"loss": 4.1694, "grad_norm": 0.5848075151443481, "learning_rate": 2.2105263157894733e-05, "epoch": 4.657894736842105, "step": 177}, {"loss": 4.3451, "grad_norm": 0.6987979412078857, "learning_rate": 2.0526315789473685e-05, "epoch": 4.684210526315789, "step": 178}, {"loss": 4.2202, "grad_norm": 0.5744144320487976, "learning_rate": 1.894736842105263e-05, "epoch": 4.7105263157894735, "step": 179}, {"loss": 4.2457, "grad_norm": 0.5571355819702148, "learning_rate": 1.7368421052631577e-05, "epoch": 4.7368421052631575, "step": 180}, {"loss": 4.1458, "grad_norm": 0.7064899206161499, "learning_rate": 1.5789473684210522e-05, "epoch": 4.7631578947368425, "step": 181}, {"loss": 4.3475, "grad_norm": 0.6128596067428589, "learning_rate": 1.4210526315789473e-05, "epoch": 4.7894736842105265, "step": 182}, {"loss": 4.3062, "grad_norm": 0.613821804523468, "learning_rate": 1.2631578947368419e-05, "epoch": 4.815789473684211, "step": 183}, {"loss": 4.2189, "grad_norm": 0.5649528503417969, "learning_rate": 1.1052631578947366e-05, "epoch": 4.842105263157895, "step": 184}, {"loss": 4.2107, "grad_norm": 0.5730451345443726, "learning_rate": 9.473684210526315e-06, "epoch": 4.868421052631579, "step": 185}, {"loss": 4.1959, "grad_norm": 0.5473831295967102, "learning_rate": 7.894736842105261e-06, "epoch": 4.894736842105263, "step": 186}, {"loss": 4.1674, "grad_norm": 0.6045023202896118, "learning_rate": 6.3157894736842095e-06, "epoch": 4.921052631578947, "step": 187}, {"loss": 4.1637, "grad_norm": 0.5644898414611816, "learning_rate": 4.736842105263158e-06, "epoch": 4.947368421052632, "step": 188}, {"loss": 4.3202, "grad_norm": 0.6141529083251953, "learning_rate": 3.1578947368421047e-06, "epoch": 4.973684210526316, "step": 189}, {"loss": 4.2737, "grad_norm": 0.6666284203529358, "learning_rate": 1.5789473684210524e-06, "epoch": 5.0, "step": 190}, {"train_runtime": 2279.8733, "train_samples_per_second": 0.329, "train_steps_per_second": 0.083, "total_flos": 257803223040000.0, "train_loss": 10.555871757708097, "epoch": 5.0, "step": 190}]